static int arcmsr_probe(struct pci_dev *pdev, const struct pci_device_id *id) struct Scsi_Host * host ; struct AdapterControlBlock * acb ; int error ; error = pci_enable_device ( pdev ); if ( error )  host = scsi_host_alloc ( & arcmsr_scsi_host_template , sizeof ( struct AdapterControlBlock ) ); if ( ! host )  error = pci_set_dma_mask ( pdev , DMA_BIT_MASK ( 64 ) ); if ( error )  error = pci_set_dma_mask ( pdev , DMA_BIT_MASK ( 32 ) ); if ( error )  acb = ( struct AdapterControlBlock * ) host -> hostdata; memset ( acb , 0 , sizeof ( struct AdapterControlBlock ) ); acb -> pdev = pdev; acb -> host = host; error = pci_request_regions ( pdev , "arcmsr" ); if ( error )  acb -> acb_flags |= ( ACB_F_MESSAGE_WQBUFFER_CLEARED | ACB_F_MESSAGE_RQBUFFER_CLEARED | ACB_F_MESSAGE_WQBUFFER_READED ); acb -> acb_flags &= ~ACB_F_SCSISTOPADAPTER; acb -> adapter_type = id -> driver_data; error = arcmsr_remap_pciregion ( acb ); static bool arcmsr_remap_pciregion(struct AdapterControlBlock *acb) struct pci_dev * pdev = acb -> pdev ; switch ( acb -> adapter_type )  acb -> pmuA = ioremap ( pci_resource_start ( pdev , 0 ) , pci_resource_len ( pdev , 0 ) ); if ( ! acb -> pmuA )  return false ; void __iomem * mem_base0 , * mem_base1 ; mem_base0 = ioremap ( pci_resource_start ( pdev , 0 ) , pci_resource_len ( pdev , 0 ) ); if ( ! mem_base0 )  return false ; mem_base1 = ioremap ( pci_resource_start ( pdev , 2 ) , pci_resource_len ( pdev , 2 ) ); if ( ! mem_base1 )  return false ; acb -> mem_base0 = mem_base0; acb -> mem_base1 = mem_base1; acb -> pmuC = ioremap_nocache ( pci_resource_start ( pdev , 1 ) , pci_resource_len ( pdev , 1 ) ); if ( ! acb -> pmuC )  return false ; if ( readl ( & acb -> pmuC -> outbound_doorbell ) & ARCMSR_HBCMU_IOP2DRV_MESSAGE_CMD_DONE )  return true ; void __iomem * mem_base0 ; unsigned long addr , range , flags ; addr = ( unsigned long ) pci_resource_start ( pdev , 0 ); range = pci_resource_len ( pdev , 0 ); mem_base0 = ioremap ( addr , range ); if ( ! mem_base0 )  return false ; return true ; if ( ! error )  error = arcmsr_alloc_io_queue ( acb ); static bool arcmsr_alloc_io_queue(struct AdapterControlBlock *acb) bool rtn = true ; void * dma_coherent ; dma_addr_t dma_coherent_handle ; struct pci_dev * pdev = acb -> pdev ; switch ( acb -> adapter_type )  struct MessageUnit_B * reg ; acb -> roundup_ccbsize = roundup ( sizeof ( struct MessageUnit_B ) , 32 ); dma_coherent = dma_zalloc_coherent ( & pdev -> dev , acb -> roundup_ccbsize , & dma_coherent_handle , GFP_KERNEL ); if ( ! dma_coherent )  return false ; acb -> dma_coherent_handle2 = dma_coherent_handle; acb -> dma_coherent2 = dma_coherent; reg = ( struct MessageUnit_B * ) dma_coherent; acb -> pmuB = reg; acb -> roundup_ccbsize = roundup ( sizeof ( struct MessageUnit_D ) , 32 ); dma_coherent = dma_zalloc_coherent ( & pdev -> dev , acb -> roundup_ccbsize , & dma_coherent_handle , GFP_KERNEL ); if ( ! dma_coherent )  return false ; return rtn ; if ( ! error )  error = arcmsr_get_firmware_spec ( acb ); static bool arcmsr_get_firmware_spec(struct AdapterControlBlock *acb) bool rtn = false ; switch ( acb -> adapter_type )  rtn = arcmsr_hbaA_get_config ( acb ); static bool arcmsr_hbaA_get_config(struct AdapterControlBlock *acb) if ( ! arcmsr_hbaA_wait_msgint_ready ( acb ) )  static uint8_t arcmsr_hbaA_wait_msgint_ready(struct AdapterControlBlock *acb) struct MessageUnit_A __iomem * reg = acb -> pmuA ; int i ; for (i = 0; i < 2000; i++) if ( readl ( & reg -> outbound_intstatus ) & ARCMSR_MU_OUTBOUND_MESSAGE0_INT )  return true ; return false ; return false ; return true ; rtn = arcmsr_hbaB_get_config ( acb ); static bool arcmsr_hbaB_get_config(struct AdapterControlBlock *acb) if ( ! arcmsr_hbaB_wait_msgint_ready ( acb ) )  static uint8_t arcmsr_hbaB_wait_msgint_ready(struct AdapterControlBlock *acb) struct MessageUnit_B * reg = acb -> pmuB ; int i ; for (i = 0; i < 2000; i++) if ( readl ( reg -> iop2drv_doorbell ) & ARCMSR_IOP2DRV_MESSAGE_CMD_DONE )  return true ; return false ; return false ; if ( ! arcmsr_hbaB_wait_msgint_ready ( acb ) )  static uint8_t arcmsr_hbaB_wait_msgint_ready(struct AdapterControlBlock *acb) struct MessageUnit_B * reg = acb -> pmuB ; int i ; if ( readl ( reg -> iop2drv_doorbell ) & ARCMSR_IOP2DRV_MESSAGE_CMD_DONE )  return true ; return false ; return false ; return true ; rtn = arcmsr_hbaC_get_config ( acb ); static bool arcmsr_hbaC_get_config(struct AdapterControlBlock *pACB) struct MessageUnit_C __iomem * reg = pACB -> pmuC ; for (Index = 0; Index < 2000; Index++) if ( readl ( & reg -> outbound_doorbell ) & ARCMSR_HBCMU_IOP2DRV_MESSAGE_CMD_DONE )  if ( Index >= 2000 )  return false ; return true ; rtn = arcmsr_hbaD_get_config ( acb ); static bool arcmsr_hbaD_get_config(struct AdapterControlBlock *acb) if ( ! arcmsr_hbaD_wait_msgint_ready ( acb ) )  static bool arcmsr_hbaD_wait_msgint_ready(struct AdapterControlBlock *pACB) struct MessageUnit_D * reg = pACB -> pmuD ; int i ; for (i = 0; i < 2000; i++) if ( readl ( reg -> outbound_doorbell ) & ARCMSR_ARC1214_IOP2DRV_MESSAGE_CMD_DONE )  return true ; return false ; return false ; return true ; return rtn ; if ( ! error )  error = arcmsr_alloc_ccb_pool ( acb ); static int arcmsr_alloc_ccb_pool(struct AdapterControlBlock *acb) struct pci_dev * pdev = acb -> pdev ; void * dma_coherent ; dma_addr_t dma_coherent_handle ; unsigned long roundup_ccbsize ; unsigned long max_xfer_len ; unsigned long max_sg_entrys ; uint32_t firm_config_version ; for (i = 0; i < ARCMSR_MAX_TARGETID; i++) for (j = 0; j < ARCMSR_MAX_TARGETLUN; j++) acb -> devstate [ i ] [ j ] = ARECA_RAID_GONE; max_xfer_len = ARCMSR_MAX_XFER_LEN; max_sg_entrys = ARCMSR_DEFAULT_SG_ENTRIES; firm_config_version = acb -> firm_cfg_version; if ( ( firm_config_version & 0xFF ) >= 3 )  max_xfer_len = ( ARCMSR_CDB_SG_PAGE_LENGTH << ( ( firm_config_version >> 8 ) & 0xFF ) ) * 1024; max_sg_entrys = ( max_xfer_len / 4096 ); acb -> host -> max_sectors = max_xfer_len / 512; acb -> host -> sg_tablesize = max_sg_entrys; roundup_ccbsize = roundup ( sizeof ( struct CommandControlBlock ) + ( max_sg_entrys - 1 ) * sizeof ( struct SG64ENTRY ) , 32 ); acb -> uncache_size = roundup_ccbsize * ARCMSR_MAX_FREECCB_NUM; dma_coherent = dma_alloc_coherent ( & pdev -> dev , acb -> uncache_size , & dma_coherent_handle , GFP_KERNEL ); if ( ! dma_coherent )  acb -> dma_coherent = dma_coherent; acb -> dma_coherent_handle = dma_coherent_handle; memset ( dma_coherent , 0 , acb -> uncache_size ); ccb_tmp = dma_coherent; acb -> vir2phy_offset = ( unsigned long ) dma_coherent - ( unsigned long ) dma_coherent_handle; switch ( acb -> adapter_type )  ccb_tmp -> cdb_phyaddr = cdb_phyaddr >> 5; ccb_tmp -> cdb_phyaddr = cdb_phyaddr; acb -> pccb_pool [ i ] = ccb_tmp; ccb_tmp -> acb = acb; INIT_LIST_HEAD ( & ccb_tmp -> list ); list_add_tail ( & ccb_tmp -> list , & acb -> ccb_free_list ); ccb_tmp = ( struct CommandControlBlock * ) ( ( unsigned long ) ccb_tmp + roundup_ccbsize ); 